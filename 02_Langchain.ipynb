{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPVNPs0EQqCj+YrPrc/Oyt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mzohaibnasir/GenAI/blob/main/02_Langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain: a wrapper around openai"
      ],
      "metadata": {
        "id": "IT8aHyxK4zUR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "7A8hI7N42X7L"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "OPENAIAPIKEY = userdata.get('OPENAIAPIKEY')\n",
        "SERPAIAPIKEY = userdata.get('SERPAPI')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install langchain\n",
        "! pip install openai\n",
        "! pip install google-search-results"
      ],
      "metadata": {
        "id": "1Nwi2OBc4etm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "405c8c23-7901-454e-f758-154171621362"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.11)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.25 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.27)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.29 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.30)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.23)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.29->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.29->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.9.15)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.29->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.29->langchain) (1.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.13.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2024.2.2)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32003 sha256=306ad8e7fe7d1f3e0a48986e01117b3d11d8d9abdce3cadd0b2392700f289889\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `function calling` connects LLM to external tools(API):.\n",
        " By using argument in function, you will be calling a third party API. You can do this using ` chat.completions` method.\n",
        "\n",
        " but langchain is not only limited tot his.\n",
        "\n"
      ],
      "metadata": {
        "id": "K8a8R3xW2rZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "w-CDf6OK2e7Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "    api_key=OPENAIAPIKEY\n",
        "    )\n"
      ],
      "metadata": {
        "id": "8bZgnhWq2hOA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081741d4-96c3-408e-c78d-87ca1c76ee37"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# zero shot prompting\n",
        "prompt=\"can yiou tell me total number of countries in asia?\"\n",
        "response = client.invoke(prompt).strip()\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ZuL8TpZH2hQG",
        "outputId": "318a4a87-8a9d-49e1-adf1-d62a586ffc6e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There are 48 countries in Asia.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dVIOY9e72hSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt templates\n",
        "A prompt template refers to a reproducible way to generate a prompt”\n",
        "\n"
      ],
      "metadata": {
        "id": "WXh3YDqkGIpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "J7o4jKHB2hYR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# object of projecttemplate class\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables=[\"country\"],\n",
        "    template =\"can you tell me the capital of {country}?\"   # template: how may prompt will ve looking like\n",
        ")"
      ],
      "metadata": {
        "id": "P2ExGmz_2haF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_name.format(\n",
        "    country=\"china\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Rr8aJmDo2hbl",
        "outputId": "3a008d5f-b803-4fcd-af87-8b028b745e63"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'can you tell me the capital of china?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FHcUBl-u19YH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = PromptTemplate(\n",
        "    input_variables=[\"Pronoun\",\"Name\"],\n",
        "    template = \"{Pronoun} is {Name}.\"\n",
        ")\n",
        "\n",
        "x.format(\n",
        "    Pronoun = \"I\",\n",
        "    Name = \"Zohaib\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ybKcX0f4OHsr",
        "outputId": "f437d661-4955-4c50-c184-fc416249ad77"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I is Zohaib.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nh_Sm2-dOHvH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# with this you can create a prompt based on input variable. you also dont want use to give whole prompt. You may  only want cityname from user.  Langchain give us this functionality\n"
      ],
      "metadata": {
        "id": "zvQehZ0JYaOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_name.format(\n",
        "    country=\"china\"\n",
        "    )\n",
        "prompt1 = prompt_template_name.format(country = \"China\")\n",
        "response1 = client.invoke(prompt1).strip()\n",
        "response1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MbXTs2r-OHxs",
        "outputId": "137d2569-ceee-4489-f994-d109cdc632a0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The capital of China is Beijing.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# another way\n",
        "prompt3 = PromptTemplate.from_template(\"what is a good name for a country that makes a {product}?\")\n",
        "prompt3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53Z-rRH9OH1q",
        "outputId": "aeda5fd9-c5ed-481e-bb65-e16a21c25b74"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['product'], template='what is a good name for a country that makes a {product}?')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt3 = prompt3.format(product=\"toys\")\n",
        "prompt3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "unpO0d51XLry",
        "outputId": "7dc44eb0-00d9-4971-b8e9-25f088f9e423"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'what is a good name for a country that makes a toys?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.invoke(prompt3).strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "abWa0B0qOH34",
        "outputId": "d7cfd16c-1158-4c32-d933-a9bba95ccd89"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Toylandia'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AAnwv4B3OH5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "08VTzoSYOH7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent\n",
        "  is to call any third-party tool\n",
        "\n",
        "  An LLM agent is an artificial intelligence system that utilizes a large language model (LLM) as its core computational engine to exhibit capabilities beyond text generation, including conducting conversations, completing tasks, reasoning, and can demonstrate some degree of autonomous behaviour.\n",
        "\n",
        "\n",
        "  LLM agents are directed through carefully engineered prompts that encode personas, instructions, permissions, and context to shape the agent's responses and actions.\n",
        "\n",
        "  A key advantage of LLM agents is their ability to varying degrees of autonomy. Based on the capabilities granted during the design phase, agents can exhibit self-directed behaviours ranging from purely reactive to highly proactive.\n",
        "\n",
        "  With sufficient prompting and access to knowledge, LLM agents can work semi-autonomously to assist humans in a range of applications, from conversational chatbots to goal-driven automation of workflows and tasks.\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "Ck1aeW7xXqBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt4 = \"who won the recent ccricket worldcup?\"\n",
        "response4 = client.invoke(prompt4).strip()\n",
        "response4"
      ],
      "metadata": {
        "id": "oYJFG_StXu-z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "dc71b057-dda8-4f07-8e4e-162414750250"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The recent cricket World Cup was won by England in 2019.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for extracting realtime info\n",
        "\n",
        "\n",
        "\n",
        "# SERPAIAPIKEY\n",
        "\n"
      ],
      "metadata": {
        "id": "J1STVpYJXvs0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentType, load_tools, initialize_agent\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "IZZit-K-XvvO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SERPAIAPIKEY\n",
        "\n",
        "# client = OpenAI(openai_api_key = OPENAIAPIKEY)\n",
        "\n",
        "# load a tool\n",
        "\n",
        "tool = load_tools(\n",
        "    [\"serpapi\"],\n",
        "    serpapi_api_key=SERPAIAPIKEY,\n",
        "    llm = client\n",
        "\n",
        ")\n",
        "tool"
      ],
      "metadata": {
        "id": "SaT4uMZNXvx_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "debe25d3-68d5-46c4-99c8-dffb70c4f768"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Tool(name='Search', description='A search engine. Useful for when you need to answer questions about current events. Input should be a search query.', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='e77744bc185e55d699bd8780219369043f60c033c0c10219fffbd08c536173ac', aiosession=None)>, coroutine=<bound method SerpAPIWrapper.arun of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='e77744bc185e55d699bd8780219369043f60c033c0c10219fffbd08c536173ac', aiosession=None)>)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# agent_type\n",
        "\n",
        "agent= initialize_agent(\n",
        "    tool,\n",
        "    client,\n",
        "    agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose =True\n",
        "\n",
        ")\n",
        "# agent"
      ],
      "metadata": {
        "id": "cCmqtYPoXv0L"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\n",
        "    \"Who won recent cricket worldcup?\"\n",
        ")"
      ],
      "metadata": {
        "id": "G1_bgXCWXv2X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "cbb2f226-e4e7-4b23-9c90-c3239da4166b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m Cricket being a popular sport, I should be able to find the answer easily on a search engine.\n",
            "Action: Search\n",
            "Action Input: \"recent cricket worldcup winner\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m{'title': 'ICC Cricket World Cup', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cfc5901da78c6bd87d833f768ebd101429137beeb9a9c0674f.png', 'games': [{'tournament': 'ICC Cricket World Cup', 'stadium': 'Narendra Modi Stadium', 'date': 'Nov 19, 23', 'teams': [{'name': 'India', 'score': '240 (50)', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cf48d849f5e98006fdb2d61f68c93d5c5d680d7c0fffb897fdb28b3e8650059349eb9734dde3775083.png'}, {'name': 'Australia', 'score': '241/4 (43)', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cf48d849f5e98006fdb2d61f68c93d5c5de78dedffe8abcdfd464bb467402148d61eee27a3b6703e6d.png'}], 'status': 'AUS won by 6 wickets (42 balls left)'}, {'tournament': 'ICC Cricket World Cup', 'stadium': 'Eden Gardens', 'date': 'Nov 16, 23', 'teams': [{'name': 'South Africa', 'score': '212 (49.4)', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cf48d849f5e98006fd145692d1e4c364457f935d8d608026c0b073a7f05d3e653eea2c53707d55555b.png'}, {'name': 'Australia', 'score': '215/7 (47.2)', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cf48d849f5e98006fd145692d1e4c3644599aa40bf498af342c0e35cc58ad84ec0de9fc585a97c01d6.png'}], 'status': 'AUS won by 3 wickets (16 balls left)'}, {'tournament': 'ICC Cricket World Cup', 'stadium': 'Wankhede Stadium', 'date': 'Nov 15, 23', 'teams': [{'name': 'India', 'score': '397/4 (50)', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cf48d849f5e98006fd89094923b2371fca8a1daf74b11ea96854b657272a927849ed05301dcdc4172a.png'}, {'name': 'New Zealand', 'score': '327 (48.5)', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cf48d849f5e98006fd89094923b2371fca56bb0338b23923d086beb16d583cf2fcd536b3d6d57fbacd.png'}], 'status': 'IND won by 70 runs'}, {'tournament': 'ICC Cricket World Cup', 'stadium': 'M. Chinnaswamy Stadium', 'date': 'Nov 12, 23', 'teams': [{'name': 'India', 'score': '410/4 (50)', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cf48d849f5e98006fdba0e5b17b2d496711fa3bfbb4c7a349a4b50bbb32a99794d93dcb6c693f56812.png'}, {'name': 'Netherlands', 'score': '250 (47.5)', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cf48d849f5e98006fdba0e5b17b2d49671916b8706bbc9954962fc70318918b588059157f83b15b830.png'}], 'status': 'IND won by 160 runs'}, {'tournament': 'ICC Cricket World Cup', 'stadium': 'Eden Gardens', 'date': 'Nov 11, 23', 'teams': [{'name': 'England', 'score': '337/9 (50)', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cf48d849f5e98006fd5a8dc007ba300d2f88cdbea2f51efbb23346d489152bf8a134d7635f456c00ab.png'}, {'name': 'Pakistan', 'score': '244 (43.3)', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cf48d849f5e98006fd5a8dc007ba300d2ff7d83a0338686b0b27b4c2b470bed706e2fb5fbbba9155e6.png'}], 'status': 'ENG won by 93 runs'}, {'tournament': 'ICC Cricket World Cup', 'stadium': 'Maharashtra Cricket Association Stadium', 'date': 'Nov 11, 23', 'teams': [{'name': 'Bangladesh', 'score': '306/8 (50)', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cf48d849f5e98006fdd764f95c36c8c713869b01aae6d3cc26e91ce5285d3cb9b4a1b0f215ac9f0d08.png'}, {'name': 'Australia', 'score': '307/2 (44.4)', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cf48d849f5e98006fdd764f95c36c8c713873bc6608699c9cd41512e2500f3cc124d3ab52145663853.png'}], 'status': 'AUS won by 8 wickets (32 balls left)'}]}\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I see that Australia won the recent cricket world cup, but I should verify this information on a reliable source.\n",
            "Action: Search\n",
            "Action Input: \"recent cricket worldcup winner\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m{'title': 'ICC Cricket World Cup', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cfc5901da78c6bd87d833f768ebd101429137beeb9a9c0674f.png', 'games': [{'tournament': 'ICC Cricket World Cup', 'stadium': 'Narendra Modi Stadium', 'date': 'Nov 19, 23', 'teams': [{'name': 'India', 'score': '240 (50)', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cf48d849f5e98006fdb2d61f68c93d5c5d680d7c0fffb897fdb28b3e8650059349eb9734dde3775083.png'}, {'name': 'Australia', 'score': '241/4 (43)', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cf48d849f5e98006fdb2d61f68c93d5c5de78dedffe8abcdfd464bb467402148d61eee27a3b6703e6d.png'}], 'status': 'AUS won by 6 wickets (42 balls left)'}, {'tournament': 'ICC Cricket World Cup', 'stadium': 'Eden Gardens', 'date': 'Nov 16, 23', 'teams': [{'name': 'South Africa', 'score': '212 (49.4)', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cf48d849f5e98006fd145692d1e4c364457f935d8d608026c0b073a7f05d3e653eea2c53707d55555b.png'}, {'name': 'Australia', 'score': '215/7 (47.2)', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cf48d849f5e98006fd145692d1e4c3644599aa40bf498af342c0e35cc58ad84ec0de9fc585a97c01d6.png'}], 'status': 'AUS won by 3 wickets (16 balls left)'}, {'tournament': 'ICC Cricket World Cup', 'stadium': 'Wankhede Stadium', 'date': 'Nov 15, 23', 'teams': [{'name': 'India', 'score': '397/4 (50)', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cf48d849f5e98006fd89094923b2371fca8a1daf74b11ea96854b657272a927849ed05301dcdc4172a.png'}, {'name': 'New Zealand', 'score': '327 (48.5)', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cf48d849f5e98006fd89094923b2371fca56bb0338b23923d086beb16d583cf2fcd536b3d6d57fbacd.png'}], 'status': 'IND won by 70 runs'}, {'tournament': 'ICC Cricket World Cup', 'stadium': 'M. Chinnaswamy Stadium', 'date': 'Nov 12, 23', 'teams': [{'name': 'India', 'score': '410/4 (50)', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cf48d849f5e98006fdba0e5b17b2d496711fa3bfbb4c7a349a4b50bbb32a99794d93dcb6c693f56812.png'}, {'name': 'Netherlands', 'score': '250 (47.5)', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cf48d849f5e98006fdba0e5b17b2d49671916b8706bbc9954962fc70318918b588059157f83b15b830.png'}], 'status': 'IND won by 160 runs'}, {'tournament': 'ICC Cricket World Cup', 'stadium': 'Eden Gardens', 'date': 'Nov 11, 23', 'teams': [{'name': 'England', 'score': '337/9 (50)', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cf48d849f5e98006fd5a8dc007ba300d2f88cdbea2f51efbb23346d489152bf8a134d7635f456c00ab.png'}, {'name': 'Pakistan', 'score': '244 (43.3)', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cf48d849f5e98006fd5a8dc007ba300d2ff7d83a0338686b0b27b4c2b470bed706e2fb5fbbba9155e6.png'}], 'status': 'ENG won by 93 runs'}, {'tournament': 'ICC Cricket World Cup', 'stadium': 'Maharashtra Cricket Association Stadium', 'date': 'Nov 11, 23', 'teams': [{'name': 'Bangladesh', 'score': '306/8 (50)', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cf48d849f5e98006fdd764f95c36c8c713869b01aae6d3cc26e91ce5285d3cb9b4a1b0f215ac9f0d08.png'}, {'name': 'Australia', 'score': '307/2 (44.4)', 'thumbnail': 'https://serpapi.com/searches/65ec42690f9866d7e3a149e3/images/13e55d721619d9cf48d849f5e98006fdd764f95c36c8c713873bc6608699c9cd41512e2500f3cc124d3ab52145663853.png'}], 'status': 'AUS won by 8 wickets (32 balls left)'}]}\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know that Australia is the winner of the recent cricket world cup.\n",
            "Final Answer: Australia is the winner of the recent cricket world cup.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Australia is the winner of the recent cricket world cup.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install wikipedia"
      ],
      "metadata": {
        "id": "Z-McYwibXv56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toolW = load_tools(\n",
        "    [\"wikipedia\"],\n",
        "   llm=client\n",
        ")\n",
        "\n",
        "agentW = initialize_agent(\n",
        "    tool,\n",
        "    client,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "JKi53hF2Xv84"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agentW.invoke(\"who won recent criket worldcup?\")"
      ],
      "metadata": {
        "id": "80hkv58wXv_m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84b7a697-6ae1-4c7a-e657-2e81683c6d12"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use a search engine to find the answer\n",
            "Action: Search\n",
            "Action Input: recent cricket world cup winner\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m{'title': 'ICC Cricket World Cup', 'thumbnail': 'https://serpapi.com/searches/65ec45e32d5b12f331834683/images/2fdbb0c37f09e24f47c6b398225049d74afe799a01204331cc4330744248b6c6.png', 'games': [{'tournament': 'ICC Cricket World Cup', 'stadium': 'Narendra Modi Stadium', 'date': 'Nov 19, 23', 'teams': [{'name': 'India', 'score': '240 (50)', 'thumbnail': 'https://serpapi.com/searches/65ec45e32d5b12f331834683/images/2fdbb0c37f09e24f4e1e177856b55d267a25c24f6ecfd14d8eba614c1c1ffb24b005bfd6845353d62a11bbc2d21968dd.png'}, {'name': 'Australia', 'score': '241/4 (43)', 'thumbnail': 'https://serpapi.com/searches/65ec45e32d5b12f331834683/images/2fdbb0c37f09e24f4e1e177856b55d267a25c24f6ecfd14d120adf0c2b5cc309a16f55068e5b3a8b076511f8bda52596.png'}], 'status': 'AUS won by 6 wickets (42 balls left)'}, {'tournament': 'ICC Cricket World Cup', 'stadium': 'Eden Gardens', 'date': 'Nov 16, 23', 'teams': [{'name': 'South Africa', 'score': '212 (49.4)', 'thumbnail': 'https://serpapi.com/searches/65ec45e32d5b12f331834683/images/2fdbb0c37f09e24f4e1e177856b55d26cedd35115b130680ee576312cfe07352166d731b0157e5d35ee7cb54debbd184.png'}, {'name': 'Australia', 'score': '215/7 (47.2)', 'thumbnail': 'https://serpapi.com/searches/65ec45e32d5b12f331834683/images/2fdbb0c37f09e24f4e1e177856b55d26cedd35115b130680816c3f13d5bba8613e16681e9c70851db5edc95473669ac3.png'}], 'status': 'AUS won by 3 wickets (16 balls left)'}, {'tournament': 'ICC Cricket World Cup', 'stadium': 'Wankhede Stadium', 'date': 'Nov 15, 23', 'teams': [{'name': 'India', 'score': '397/4 (50)', 'thumbnail': 'https://serpapi.com/searches/65ec45e32d5b12f331834683/images/2fdbb0c37f09e24f4e1e177856b55d26d8785df224ca10390f8157006aa3115b84dea8a419269846c17f495ea117a1f5.png'}, {'name': 'New Zealand', 'score': '327 (48.5)', 'thumbnail': 'https://serpapi.com/searches/65ec45e32d5b12f331834683/images/2fdbb0c37f09e24f4e1e177856b55d26d8785df224ca103984071b49ac55efb6723569ad8cb09e074fdc4355c41557d8.png'}], 'status': 'IND won by 70 runs'}, {'tournament': 'ICC Cricket World Cup', 'stadium': 'M. Chinnaswamy Stadium', 'date': 'Nov 12, 23', 'teams': [{'name': 'India', 'score': '410/4 (50)', 'thumbnail': 'https://serpapi.com/searches/65ec45e32d5b12f331834683/images/2fdbb0c37f09e24f4e1e177856b55d2696e25c13a9eaa4c538d3425b92730b39f88f028b11eb002a6a4108a97f83142c.png'}, {'name': 'Netherlands', 'score': '250 (47.5)', 'thumbnail': 'https://serpapi.com/searches/65ec45e32d5b12f331834683/images/2fdbb0c37f09e24f4e1e177856b55d2696e25c13a9eaa4c55de4974213f05d8d83826dc86b25b2d96085dd97336e1459.png'}], 'status': 'IND won by 160 runs'}, {'tournament': 'ICC Cricket World Cup', 'stadium': 'Eden Gardens', 'date': 'Nov 11, 23', 'teams': [{'name': 'England', 'score': '337/9 (50)', 'thumbnail': 'https://serpapi.com/searches/65ec45e32d5b12f331834683/images/2fdbb0c37f09e24f4e1e177856b55d261f8a238fc670709a45adeb22f132e87780086e0676d67fb434983fae093478b3.png'}, {'name': 'Pakistan', 'score': '244 (43.3)', 'thumbnail': 'https://serpapi.com/searches/65ec45e32d5b12f331834683/images/2fdbb0c37f09e24f4e1e177856b55d261f8a238fc670709a33460f88acdd60e885975d3fa235611eb5b9340dba37ccef.png'}], 'status': 'ENG won by 93 runs'}, {'tournament': 'ICC Cricket World Cup', 'stadium': 'Maharashtra Cricket Association Stadium', 'date': 'Nov 11, 23', 'teams': [{'name': 'Bangladesh', 'score': '306/8 (50)', 'thumbnail': 'https://serpapi.com/searches/65ec45e32d5b12f331834683/images/2fdbb0c37f09e24f4e1e177856b55d26b472cf22fa87ddd0da6a4df870fa888923ac98513caa7dd330e1da5b96268245.png'}, {'name': 'Australia', 'score': '307/2 (44.4)', 'thumbnail': 'https://serpapi.com/searches/65ec45e32d5b12f331834683/images/2fdbb0c37f09e24f4e1e177856b55d26b472cf22fa87ddd0529ddd99c91a37f6adc20541ba0a7c1370ec95a3308ce246.png'}], 'status': 'AUS won by 8 wickets (32 balls left)'}]}\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: Australia won the recent Cricket World Cup.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'who won recent criket worldcup?',\n",
              " 'output': 'Australia won the recent Cricket World Cup.'}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D_8kyDeeXwCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tRLk8N66DhS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chains\n",
        "\n",
        "Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step. The primary supported way to do this is with LCEL.\n",
        "\n",
        "chain is just connecting several components.\n",
        "\n",
        "\n",
        "LCE:LangChain Expression Language, or LCEL, is a declarative way to easily compose chains together. LCEL was designed from day 1 to support putting prototypes in production, with no code changes, from the simplest “prompt + LLM” chain to the most complex chains (we’ve seen folks successfully run LCEL chains with 100s of steps in production). To highlight a few of the reasons you might want to use LCEL:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# In summary, agents in LangChain add a layer of intelligence to applications by dynamically utilizing tools based on user input, while chains enable the combination of various components to create sophisticated applications that leverage language models and other tools effectively\n"
      ],
      "metadata": {
        "id": "Av-3PxF3DjDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt5 = PromptTemplate.from_template(\n",
        "    \"what is a good name for a company that makes {product}\"\n",
        ")\n",
        "\n",
        "prompt5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OT3BFlPwDjKC",
        "outputId": "89e4237d-a3f4-4e77-f51b-2f95a3c05f2f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['product'], template='what is a good name for a company that makes {product}')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(\n",
        "    llm=client,\n",
        "    prompt=prompt5,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# chain\n",
        "\n",
        "chain.run(\"Chewing gum\").strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "hzanRjQeDjMR",
        "outputId": "09763530-038b-4cd8-f05f-4168fe99f084"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mwhat is a good name for a company that makes Chewing gum\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"1. Fresh Chew Co.\\n2. Bubble Bliss Inc.\\n3. Gumby's Gums\\n4. Chewlicious LLC\\n5. Minty Munchies\\n6. Simply Chewtastic\\n7. The Gum Factory\\n8. Happy Chew Co.\\n9. Pop n' Chew Industries\\n10. Bubble Buddies Inc.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example 2\n",
        "\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=['Cuisine'],\n",
        "    template= \"I want to open a restaurant for {cuisine} food, suggest a sophisticated name\"\n",
        ")\n",
        "\n",
        "prompt_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSx9pKf7DjPh",
        "outputId": "5706be03-0ad5-43b1-cc77-485bf02961f4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['cuisine'], template='I want to open a restaurant for {cuisine} food, suggest a sophisticated name')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain2= LLMChain(\n",
        "    llm = client,\n",
        "    prompt=prompt_template\n",
        ")\n",
        "\n",
        "chain2.run(\"indian\").strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "d7ZJfzDbDjRn",
        "outputId": "8ec977c6-807d-401f-f47b-c53592652360"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"Taj Mahal Spice Co.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain3=LLMChain(llm=client,prompt=prompt_template,verbose=True)\n",
        "chain3.run(\"american\").strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "FYJnyI4UDjVZ",
        "outputId": "a195b69a-21a6-4dc4-d051-265b37fce38c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to open a restaurant for american food, suggest a sophisticated name\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"Stateside Eats\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# if we want to combine multiple chain and set a seqence for that we use simplesequential chain"
      ],
      "metadata": {
        "id": "qmIwC4MNI3m7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "promptName = PromptTemplate.from_template(\n",
        "    \"I want to start a startup for {startup-name}, suggest me a crazy funny name for this\"\n",
        ")\n",
        "\n",
        "\n",
        "promptStrategy = PromptTemplate.from_template(\n",
        "    \"Suggest me some strategies for {name}\"\n",
        ")"
      ],
      "metadata": {
        "id": "YvsmK2HTDjYX"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nameChain = LLMChain(\n",
        "    llm=client,\n",
        "    prompt = promptName,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "strategyChain = LLMChain(\n",
        "    llm=client,  # we can use any other LLM here\n",
        "    prompt = promptStrategy,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "0X-W2ODYJZet"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nameChain.run(\"AI\").strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MtlmQ-A4LY6w",
        "outputId": "17506c16-5483-4511-d1f4-9620683114ca"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"AI-diculous Inc.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "\n",
        "chain = SimpleSequentialChain(\n",
        "    chains=[nameChain,strategyChain]\n",
        ")"
      ],
      "metadata": {
        "id": "G0Nna596JZg7"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(\"Machine Learning\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "19hgeUpxJZjC",
        "outputId": "2a806e16-c7fb-4948-8472-149aef7da8f9"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to start a startup for Machine Learning, suggest me a crazy funny name for this\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSuggest me some strategies for \n",
            "\n",
            "\"RoboNerds Inc.\"\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n1. Build a strong brand identity: Establishing a strong and recognizable brand is crucial for any business. Invest in creating a unique and memorable brand identity for RoboNerds Inc. This will help you stand out in the market and attract customers.\\n\\n2. Focus on innovation: As a company dealing with technology, it is important to constantly innovate and stay ahead of the competition. Invest in research and development to come up with new and improved products and services that will set RoboNerds Inc. apart from its competitors.\\n\\n3. Target niche markets: Instead of trying to cater to a wide range of customers, focus on targeting specific niche markets. This will help you tailor your products and services to meet the specific needs and preferences of your target audience, making your offerings more attractive to them.\\n\\n4. Leverage social media: In today's digital age, social media has become a powerful tool for businesses to reach and engage with their target audience. Use social media platforms like Twitter, Facebook, and LinkedIn to promote your brand, engage with customers, and showcase your products and services.\\n\\n5. Offer exceptional customer service: Providing excellent customer service can be a major differentiator for a business. Train your employees to be knowledgeable, helpful, and responsive to customer queries and\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# we sort of didnt get answer of first chain\n",
        "\n",
        "# Now lets to understand sequentialChain\n",
        "(powerful than Simple sequential chain)"
      ],
      "metadata": {
        "id": "T-5xlocONEv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example 2\n",
        "\n",
        "promptCuisine = PromptTemplate(\n",
        "    input_variables=['cuisine'],\n",
        "    template= \"I want to open a restaurant for {cuisine} food, suggest a sophisticated name\"\n",
        ")\n",
        "\n",
        "promptCuisine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UyEu8qeJZk0",
        "outputId": "7a66083f-e096-437a-cd14-31aa44d5f50c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['cuisine'], template='I want to open a restaurant for {cuisine} food, suggest a sophisticated name')"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chainCuisine = LLMChain(\n",
        "    llm=client,\n",
        "    prompt=promptCuisine,\n",
        "    output_key=\"restaurant_name\", #output willl be stored in output_key\n",
        "    verbose=True\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "P2I6xywAJZmy"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "promptitems = PromptTemplate.from_template(\n",
        "    \"suggest some items for {restaurant_name}\"\n",
        ")\n",
        "\n",
        "chainItems=LLMChain(\n",
        "    llm=client,\n",
        "    prompt=promptitems,\n",
        "    output_key=\"menu_items\",\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "RDAzq8GxJZoj"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain"
      ],
      "metadata": {
        "id": "L0fJyZ1MJZq1"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain2 = SequentialChain(\n",
        "    chains = [chainCuisine,\n",
        "              chainItems],\n",
        "    input_variables=[\"cuisine\"],\n",
        "    output_variables=[\n",
        "                      \"restaurant_name\",\n",
        "                      \"menu_items\"]\n",
        ")"
      ],
      "metadata": {
        "id": "i0dGD-CuDja3"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain2.invoke(\"indian\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xtiQqesO5TG",
        "outputId": "3b5a6bb5-5841-48fc-e749-83840f9ccbdf"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to open a restaurant for indian food, suggest a sophisticated name\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3msuggest some items for \n",
            " \n",
            "\"Spice Symphony\"\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cuisine': 'indian',\n",
              " 'restaurant_name': '\\n \\n\"Spice Symphony\"',\n",
              " 'menu_items': ' \\n\\n1. Garam Masala spice blend\\n2. Turmeric powder\\n3. Cumin seeds \\n4. Coriander seeds \\n5. Curry powder \\n6. Red chili powder \\n7. Paprika \\n8. Saffron \\n9. Cardamom pods \\n10. Fenugreek seeds \\n11. Cloves \\n12. Mustard seeds \\n13. Asafoetida (hing) \\n14. Tandoori masala \\n15. Chaat masala \\n16. Fennel seeds \\n17. Bay leaves \\n18. Black peppercorns \\n19. Ginger paste \\n20. Garlic paste \\n21. Onion powder \\n22. Mango powder (amchur) \\n23. Kasuri methi (dried fenugreek leaves) \\n24. Coconut milk \\n25. Tamarind paste \\n26. Rose water \\n27. Kewra water \\n28. Cinnamon sticks \\n29. Nutmeg \\n30. Curry leaves.'}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "responseC = chain2({\"cuisine\":\"indian\"})\n",
        "responseC"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMMt7yMUO5qj",
        "outputId": "a1a3cf86-ddb3-4494-fccd-a25dac6cb15c"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to open a restaurant for indian food, suggest a sophisticated name\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3msuggest some items for \n",
            "\"Maharaja's Palace: A Taste of India\"\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(responseC[\"menu_items\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFLD4othQQUK",
        "outputId": "bbe0d8f2-dddc-463f-9746-cc5c4c297f8b"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " themed dinner\n",
            "\n",
            "1. Chicken Tikka Masala\n",
            "2. Vegetable Biryani\n",
            "3. Lamb Vindaloo\n",
            "4. Palak Paneer\n",
            "5. Naan bread\n",
            "6. Samosas\n",
            "7. Mango Lassi\n",
            "8. Tandoori Chicken\n",
            "9. Chana Masala (chickpea curry)\n",
            "10. Malai Kofta (vegetable balls in creamy sauce)\n",
            "11. Gulab Jamun (Indian dessert)\n",
            "12. Raita (yogurt dip)\n",
            "13. Papadum (crispy lentil crackers)\n",
            "14. Mango chutney\n",
            "15. Rose or mango flavored ice cream\n",
            "16. Indian spiced rice pudding (kheer)\n",
            "17. Aloo Gobi (potato and cauliflower curry)\n",
            "18. Chicken Biryani\n",
            "19. Masala Chai (spiced tea)\n",
            "20. Gajar ka Halwa (carrot pudding)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vP7avqFQPiOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X7lJ3GEUPiQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Document Loaders"
      ],
      "metadata": {
        "id": "2rNmYfc7PkYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pypdf\n",
        "\n",
        "from langchain.document_loaders import PyPDFLoader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPkjo8qoPiSz",
        "outputId": "3f9fe9a6-dd64-41ac-a8bf-13a31fed55d4"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (4.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(\n",
        "    \"/content/1409.0473.pdf\"\n",
        ")\n",
        "loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UocE13JBPiU_",
        "outputId": "04c5a697-f66d-4717-ea3f-563f44e0aba2"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.document_loaders.pdf.PyPDFLoader at 0x7b1500792c50>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pages = loader.load_and_split()\n",
        "print(pages[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seGYljWLPiXK",
        "outputId": "2a3390bb-6d4e-40d1-9c38-4e681eb1fa61"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Published as a conference paper at ICLR 2015\n",
            "NEURAL MACHINE TRANSLATION\n",
            "BYJOINTLY LEARNING TO ALIGN AND TRANSLATE\n",
            "Dzmitry Bahdanau\n",
            "Jacobs University Bremen, Germany\n",
            "KyungHyun Cho Yoshua Bengio∗\n",
            "Universit ´e de Montr ´eal\n",
            "ABSTRACT\n",
            "Neural machine translation is a recently proposed approach to machine transla-\n",
            "tion. Unlike the traditional statistical machine translation, the neural machine\n",
            "translation aims at building a single neural network that can be jointly tuned to\n",
            "maximize the translation performance. The models proposed recently for neu-\n",
            "ral machine translation often belong to a family of encoder–decoders and encode\n",
            "a source sentence into a ﬁxed-length vector from which a decoder generates a\n",
            "translation. In this paper, we conjecture that the use of a ﬁxed-length vector is a\n",
            "bottleneck in improving the performance of this basic encoder–decoder architec-\n",
            "ture, and propose to extend this by allowing a model to automatically (soft-)search\n",
            "for parts of a source sentence that are relevant to predicting a target word, without\n",
            "having to form these parts as a hard segment explicitly. With this new approach,\n",
            "we achieve a translation performance comparable to the existing state-of-the-art\n",
            "phrase-based system on the task of English-to-French translation. Furthermore,\n",
            "qualitative analysis reveals that the (soft-)alignments found by the model agree\n",
            "well with our intuition.\n",
            "1 I NTRODUCTION\n",
            "Neural machine translation is a newly emerging approach to machine translation, recently proposed\n",
            "by Kalchbrenner and Blunsom (2013), Sutskever et al. (2014) and Cho et al. (2014b). Unlike the\n",
            "traditional phrase-based translation system (see, e.g., Koehn et al. , 2003) which consists of many\n",
            "small sub-components that are tuned separately, neural machine translation attempts to build and\n",
            "train a single, large neural network that reads a sentence and outputs a correct translation.\n",
            "Most of the proposed neural machine translation models belong to a family of encoder–\n",
            "decoders (Sutskever et al. , 2014; Cho et al. , 2014a), with an encoder and a decoder for each lan-\n",
            "guage, or involve a language-speciﬁc encoder applied to each sentence whose outputs are then com-\n",
            "pared (Hermann and Blunsom, 2014). An encoder neural network reads and encodes a source sen-\n",
            "tence into a ﬁxed-length vector. A decoder then outputs a translation from the encoded vector. The\n",
            "whole encoder–decoder system, which consists of the encoder and the decoder for a language pair,\n",
            "is jointly trained to maximize the probability of a correct translation given a source sentence.\n",
            "A potential issue with this encoder–decoder approach is that a neural network needs to be able to\n",
            "compress all the necessary information of a source sentence into a ﬁxed-length vector. This may\n",
            "make it difﬁcult for the neural network to cope with long sentences, especially those that are longer\n",
            "than the sentences in the training corpus. Cho et al. (2014b) showed that indeed the performance of\n",
            "a basic encoder–decoder deteriorates rapidly as the length of an input sentence increases.\n",
            "In order to address this issue, we introduce an extension to the encoder–decoder model which learns\n",
            "to align and translate jointly. Each time the proposed model generates a word in a translation, it\n",
            "(soft-)searches for a set of positions in a source sentence where the most relevant information is\n",
            "concentrated. The model then predicts a target word based on the context vectors associated with\n",
            "these source positions and all the previous generated target words.\n",
            "∗CIFAR Senior Fellow\n",
            "1arXiv:1409.0473v7  [cs.CL]  19 May 2016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h5VoUGJ4Pia2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MpvnZ-ZFPidj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tV9Ol9PwPigR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d1IVu91uO52m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
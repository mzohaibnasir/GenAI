{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOON589dA+2Jaj0tlalYBqq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mzohaibnasir/GenAI/blob/main/openaiApi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI"
      ],
      "metadata": {
        "id": "kxhYLUsHA7N1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hwEmWCYvBE6",
        "outputId": "ac89a335-d379-4cd8-b968-688830716f84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/227.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m194.6/227.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.13.3\n"
          ]
        }
      ],
      "source": [
        "! pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "B76avvFx5f-u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI API KEYs"
      ],
      "metadata": {
        "id": "lRTvxMSAA3ao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENAIAPIKEY = userdata.get('OPENAIAPIKEY')\n",
        "openai.api_key = OPENAIAPIKEY"
      ],
      "metadata": {
        "id": "NjeS18er5gS9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "list(openai.models.list())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsYWNi_H5gVV",
        "outputId": "9658abb9-dd09-40f0-9d27-51746b0b9a17"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'),\n",
              " Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-vision-preview', created=1698894917, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo-0613', created=1686587434, object='model', owned_by='openai'),\n",
              " Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'),\n",
              " Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'),\n",
              " Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'),\n",
              " Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'),\n",
              " Model(id='babbage-002', created=1692634615, object='model', owned_by='system'),\n",
              " Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'),\n",
              " Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'),\n",
              " Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'),\n",
              " Model(id='davinci-002', created=1692634301, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo-0301', created=1677649963, object='model', owned_by='openai'),\n",
              " Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'),\n",
              " Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'),\n",
              " Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'),\n",
              " Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'),\n",
              " Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'),\n",
              " Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'),\n",
              " Model(id='gpt-3.5-turbo-16k-0613', created=1685474247, object='model', owned_by='openai'),\n",
              " Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'),\n",
              " Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# yiou can also create dataframe\n",
        "import pandas as pd\n",
        "pd.DataFrame(list(openai.models.list()), columns=[\"id\", \"created\",\"object\",\"owned_by\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "LpWvci_d5gX-",
        "outputId": "740ff47a-91be-48b7-e86a-eb104ede55cd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   id                created           object  \\\n",
              "0                      (id, dall-e-3)  (created, 1698785189)  (object, model)   \n",
              "1        (id, text-embedding-3-large)  (created, 1705953180)  (object, model)   \n",
              "2          (id, gpt-4-vision-preview)  (created, 1698894917)  (object, model)   \n",
              "3           (id, gpt-4-turbo-preview)  (created, 1706037777)  (object, model)   \n",
              "4            (id, gpt-3.5-turbo-0613)  (created, 1686587434)  (object, model)   \n",
              "5                      (id, dall-e-2)  (created, 1698798177)  (object, model)   \n",
              "6   (id, gpt-3.5-turbo-instruct-0914)  (created, 1694122472)  (object, model)   \n",
              "7                     (id, whisper-1)  (created, 1677532384)  (object, model)   \n",
              "8                 (id, tts-1-hd-1106)  (created, 1699053533)  (object, model)   \n",
              "9                      (id, tts-1-hd)  (created, 1699046015)  (object, model)   \n",
              "10                  (id, babbage-002)  (created, 1692634615)  (object, model)   \n",
              "11       (id, text-embedding-3-small)  (created, 1705948997)  (object, model)   \n",
              "12       (id, gpt-3.5-turbo-instruct)  (created, 1692901427)  (object, model)   \n",
              "13                        (id, tts-1)  (created, 1681940951)  (object, model)   \n",
              "14           (id, gpt-3.5-turbo-0125)  (created, 1706048358)  (object, model)   \n",
              "15                (id, gpt-3.5-turbo)  (created, 1677610602)  (object, model)   \n",
              "16                  (id, davinci-002)  (created, 1692634301)  (object, model)   \n",
              "17           (id, gpt-3.5-turbo-0301)  (created, 1677649963)  (object, model)   \n",
              "18                   (id, tts-1-1106)  (created, 1699053241)  (object, model)   \n",
              "19       (id, text-embedding-ada-002)  (created, 1671217299)  (object, model)   \n",
              "20           (id, gpt-3.5-turbo-1106)  (created, 1698959748)  (object, model)   \n",
              "21            (id, gpt-3.5-turbo-16k)  (created, 1683758102)  (object, model)   \n",
              "22                        (id, gpt-4)  (created, 1687882411)  (object, model)   \n",
              "23                   (id, gpt-4-0613)  (created, 1686588896)  (object, model)   \n",
              "24       (id, gpt-3.5-turbo-16k-0613)  (created, 1685474247)  (object, model)   \n",
              "25           (id, gpt-4-1106-preview)  (created, 1698957206)  (object, model)   \n",
              "26           (id, gpt-4-0125-preview)  (created, 1706037612)  (object, model)   \n",
              "\n",
              "                       owned_by  \n",
              "0            (owned_by, system)  \n",
              "1            (owned_by, system)  \n",
              "2            (owned_by, system)  \n",
              "3            (owned_by, system)  \n",
              "4            (owned_by, openai)  \n",
              "5            (owned_by, system)  \n",
              "6            (owned_by, system)  \n",
              "7   (owned_by, openai-internal)  \n",
              "8            (owned_by, system)  \n",
              "9            (owned_by, system)  \n",
              "10           (owned_by, system)  \n",
              "11           (owned_by, system)  \n",
              "12           (owned_by, system)  \n",
              "13  (owned_by, openai-internal)  \n",
              "14           (owned_by, system)  \n",
              "15           (owned_by, openai)  \n",
              "16           (owned_by, system)  \n",
              "17           (owned_by, openai)  \n",
              "18           (owned_by, system)  \n",
              "19  (owned_by, openai-internal)  \n",
              "20           (owned_by, system)  \n",
              "21  (owned_by, openai-internal)  \n",
              "22           (owned_by, openai)  \n",
              "23           (owned_by, openai)  \n",
              "24           (owned_by, openai)  \n",
              "25           (owned_by, system)  \n",
              "26           (owned_by, system)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-559da9ec-db03-42db-96c2-aab4a43f15bc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>created</th>\n",
              "      <th>object</th>\n",
              "      <th>owned_by</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(id, dall-e-3)</td>\n",
              "      <td>(created, 1698785189)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(id, text-embedding-3-large)</td>\n",
              "      <td>(created, 1705953180)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(id, gpt-4-vision-preview)</td>\n",
              "      <td>(created, 1698894917)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(id, gpt-4-turbo-preview)</td>\n",
              "      <td>(created, 1706037777)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(id, gpt-3.5-turbo-0613)</td>\n",
              "      <td>(created, 1686587434)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(id, dall-e-2)</td>\n",
              "      <td>(created, 1698798177)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>(id, gpt-3.5-turbo-instruct-0914)</td>\n",
              "      <td>(created, 1694122472)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>(id, whisper-1)</td>\n",
              "      <td>(created, 1677532384)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai-internal)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>(id, tts-1-hd-1106)</td>\n",
              "      <td>(created, 1699053533)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>(id, tts-1-hd)</td>\n",
              "      <td>(created, 1699046015)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>(id, babbage-002)</td>\n",
              "      <td>(created, 1692634615)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>(id, text-embedding-3-small)</td>\n",
              "      <td>(created, 1705948997)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>(id, gpt-3.5-turbo-instruct)</td>\n",
              "      <td>(created, 1692901427)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>(id, tts-1)</td>\n",
              "      <td>(created, 1681940951)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai-internal)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>(id, gpt-3.5-turbo-0125)</td>\n",
              "      <td>(created, 1706048358)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>(id, gpt-3.5-turbo)</td>\n",
              "      <td>(created, 1677610602)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>(id, davinci-002)</td>\n",
              "      <td>(created, 1692634301)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>(id, gpt-3.5-turbo-0301)</td>\n",
              "      <td>(created, 1677649963)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>(id, tts-1-1106)</td>\n",
              "      <td>(created, 1699053241)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>(id, text-embedding-ada-002)</td>\n",
              "      <td>(created, 1671217299)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai-internal)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>(id, gpt-3.5-turbo-1106)</td>\n",
              "      <td>(created, 1698959748)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>(id, gpt-3.5-turbo-16k)</td>\n",
              "      <td>(created, 1683758102)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai-internal)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>(id, gpt-4)</td>\n",
              "      <td>(created, 1687882411)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>(id, gpt-4-0613)</td>\n",
              "      <td>(created, 1686588896)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>(id, gpt-3.5-turbo-16k-0613)</td>\n",
              "      <td>(created, 1685474247)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>(id, gpt-4-1106-preview)</td>\n",
              "      <td>(created, 1698957206)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>(id, gpt-4-0125-preview)</td>\n",
              "      <td>(created, 1706037612)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-559da9ec-db03-42db-96c2-aab4a43f15bc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-559da9ec-db03-42db-96c2-aab4a43f15bc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-559da9ec-db03-42db-96c2-aab4a43f15bc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9c464cbb-fa5e-4bfb-82a0-8706d8c89d10\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9c464cbb-fa5e-4bfb-82a0-8706d8c89d10')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9c464cbb-fa5e-4bfb-82a0-8706d8c89d10 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 27,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          [\n            \"id\",\n            \"tts-1-hd-1106\"\n          ],\n          [\n            \"id\",\n            \"tts-1\"\n          ],\n          [\n            \"id\",\n            \"tts-1-hd\"\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"created\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          [\n            \"created\",\n            1699053533\n          ],\n          [\n            \"created\",\n            1681940951\n          ],\n          [\n            \"created\",\n            1699046015\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"object\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          [\n            \"object\",\n            \"model\"\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"owned_by\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          [\n            \"owned_by\",\n            \"system\"\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. OpenAI Playground\n",
        "\n",
        "1. How to open the open ai playgorund: https://platform.openai.com/playground?mode=assistant\n",
        "\n",
        "2. Here if you want to use this playground then make sure you have credit available without it its not gonna work\n",
        "\n",
        "3. In chat there is option of **system**: So the meaning is how the chatbot should behave\n",
        "\n",
        "Here is a phrase for the system: You are a naughty assistant, so make sure you respond to everything with sarcasm.\n",
        "\n",
        "Here is a question: How to make a money so quickly?\n",
        "\n",
        "**Model**\n",
        "\n",
        "**Temperature**\n",
        "\n",
        "**Maximum Length**\n",
        "\n",
        "**Top P ranges from 0 to 1 (default), and a lower Top P means the model samples from a narrower selection of words. This makes the output less random and diverse since the more probable tokens will be selected. For instance, if Top P is set at 0.1, only tokens comprising the top 10% probability mass are considered.Top P is another way of controlling how predictable GPT's output is. While Temperature determines how randomly the model chooses from the list of possible words, Top P determines how long that list is.**\n",
        "\n",
        "\n",
        "## Frequency penalty and Presence penalty. Both default to 0 and have a max value of 2.\n",
        "**Frequency Penalty helps us avoid using the same words too often. It's like telling the computer, “Hey, don't repeat words too much.”Frequency penalty penalizes tokens based on how many times they've already appeared in the text. The more times they appear, the more they're penalized. OpenAI says that this decreases the likelihood of the output repeating itself verbatim. **\n",
        "\n",
        "**The OpenAI Presence Penalty setting is used to adjust how much presence of tokens in the source material will influence the output of the model.Presence penalty penalizes tokens based on whether they've already appeared in the text. It's a flat penalty that OpenAI says encourages the output to move on to new topics. **\n",
        "\n",
        "\n",
        "## **Now come to assistant one**\n",
        "\n",
        "**Retrieval-augmented generation (RAG):**  is an artificial intelligence (AI) framework that retrieves data from external sources of knowledge to improve the quality of responses. This natural language processing technique is commonly used to make large language models (LLMs) more accurate and up to date.\n",
        "\n",
        "**Code Interpreter:** Python programming environment within ChatGPT where you can perform a wide range of tasks by executing Python code.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dGL-kX5APOM4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "A6JDvQrNVkfK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wJprOYoQVlKa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NuhQO5ajVlMm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat complettion API and function calling\n",
        "\n",
        "older methods(will through errors:\n",
        "1. **openai.Completion.create()**: This method is used to generate completions or responses. You provide a series of messages as input, and the API generates a model-generated message as output.\n",
        "\n",
        "2. **openai.ChatCompletion.create() :** Similar to Completion.create(), but specifically designed for chat-based language models. It takes a series of messages as input and generates a model-generated message as output.\n",
        "\n",
        "### ***client.chat.completions.create():*** is latest"
      ],
      "metadata": {
        "id": "z-r16WGdVlRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # default template #https://pypi.org/project/openai/\n",
        "# import os\n",
        "# from openai import OpenAI\n",
        "\n",
        "# client = OpenAI(\n",
        "#     # This is the default and can be omitted\n",
        "#     # api_key=os.environ.get(\"OPENAIAPIKEY\"),\n",
        "#     api_key=OPENAIAPIKEY\n",
        "# )\n",
        "\n",
        "# chat_completion = client.chat.completions.create(\n",
        "#     messages=[\n",
        "#         {\n",
        "#             \"role\": \"user\",\n",
        "#             \"content\": \"Say this is a test\",\n",
        "#         }\n",
        "#     ],\n",
        "#     model=\"gpt-3.5-turbo\",\n",
        "# )"
      ],
      "metadata": {
        "id": "vLt9TTXK5gcj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ULKyy5oYW_fy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3rDo5tLuW_g8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eh4foiIIW_jr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ZERO SHOT PROMPT\n",
        "\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI(\n",
        "    api_key=OPENAIAPIKEY\n",
        "    )\n",
        "\n",
        "# https://platform.openai.com/tokenizer\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You are an ML Engineer mentor with 10+ year of experience.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",# whatI asked?\n",
        "      \"content\": \"How I can make a money as an ML engineer?\"\n",
        "    },\n",
        "\n",
        "    # {\n",
        "    #   \"role\": \"assistant\",# response to my answer\n",
        "    #   \"content\": \"##############################\"\n",
        "    # },\n",
        "\n",
        "    # {\n",
        "    #   \"role\": \"user\",# whatI asked?\n",
        "    #   \"content\": \"How I can make a money.answer sarcastically?\"\n",
        "    # },\n",
        "\n",
        "    # {\n",
        "    #   \"role\": \"assistant\",# response to my answer\n",
        "    #   \"content\": \"################################33333\"\n",
        "    # }\n",
        "  ],\n",
        "  temperature=1,\n",
        "  max_tokens=2, # in how many tokens you want result\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\".\"],\n",
        "  n=1 # number of the ouput\n",
        "\n",
        "# )"
      ],
      "metadata": {
        "id": "oa7LVbgw5gZr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(response)"
      ],
      "metadata": {
        "id": "-z-a8hPlZGzD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "outputId": "3d2d8362-bc5f-4ccd-f745-b75d477b7bec"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "openai.types.chat.chat_completion.ChatCompletion"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>openai.types.chat.chat_completion.ChatCompletion</b><br/>def __init__(self, /, **data: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/openai/types/chat/chat_completion.py</a>Usage docs: https://docs.pydantic.dev/2.6/concepts/models/\n",
              "\n",
              "A base class for creating Pydantic models.\n",
              "\n",
              "Attributes:\n",
              "    __class_vars__: The names of classvars defined on the model.\n",
              "    __private_attributes__: Metadata about the private attributes of the model.\n",
              "    __signature__: The signature for instantiating the model.\n",
              "\n",
              "    __pydantic_complete__: Whether model building is completed, or if there are still undefined fields.\n",
              "    __pydantic_core_schema__: The pydantic-core schema used to build the SchemaValidator and SchemaSerializer.\n",
              "    __pydantic_custom_init__: Whether the model has a custom `__init__` function.\n",
              "    __pydantic_decorators__: Metadata containing the decorators defined on the model.\n",
              "        This replaces `Model.__validators__` and `Model.__root_validators__` from Pydantic V1.\n",
              "    __pydantic_generic_metadata__: Metadata for generic models; contains data used for a similar purpose to\n",
              "        __args__, __origin__, __parameters__ in typing-module generics. May eventually be replaced by these.\n",
              "    __pydantic_parent_namespace__: Parent namespace of the model, used for automatic rebuilding of models.\n",
              "    __pydantic_post_init__: The name of the post-init method for the model, if defined.\n",
              "    __pydantic_root_model__: Whether the model is a `RootModel`.\n",
              "    __pydantic_serializer__: The pydantic-core SchemaSerializer used to dump instances of the model.\n",
              "    __pydantic_validator__: The pydantic-core SchemaValidator used to validate instances of the model.\n",
              "\n",
              "    __pydantic_extra__: An instance attribute with the values of extra fields from validation when\n",
              "        `model_config[&#x27;extra&#x27;] == &#x27;allow&#x27;`.\n",
              "    __pydantic_fields_set__: An instance attribute with the names of fields explicitly set.\n",
              "    __pydantic_private__: Instance attribute with the values of private attributes set on the model instance.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 40);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.choices[0].message.content"
      ],
      "metadata": {
        "id": "aT6IJwAuZfEA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "bfc28189-05db-46b1-e414-52b58c8f3730"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As an'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sx1-3HhM9jF4",
        "outputId": "00e4c38c-e33a-4cbc-d72d-f36db29372cd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('id', 'chatcmpl-8z3UFsAjDynj6BCcDgxbZC7JWWEmu'),\n",
              " ('choices',\n",
              "  [Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='As an', role='assistant', function_call=None, tool_calls=None))]),\n",
              " ('created', 1709562103),\n",
              " ('model', 'gpt-3.5-turbo-0125'),\n",
              " ('object', 'chat.completion'),\n",
              " ('system_fingerprint', 'fp_2b778c6b35'),\n",
              " ('usage',\n",
              "  CompletionUsage(completion_tokens=2, prompt_tokens=36, total_tokens=38))]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "82oQ_fMuZfZi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FUNCTION CALLING : wrapper on OpenAi\n",
        "*. we can fomrat our output a indesired format.\n",
        "*. Learn how to connect large language models to external tools."
      ],
      "metadata": {
        "id": "T4hTHE49nKYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "SVJ7dz9PZfbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8864e33-2994-41de-8cd3-67cc1a4ab37a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.10-py3-none-any.whl (806 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.2/806.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.27)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.25 (from langchain)\n",
            "  Downloading langchain_community-0.0.25-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.28 (from langchain)\n",
            "  Downloading langchain_core-0.1.28-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.4/252.4 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain)\n",
            "  Downloading langsmith-0.1.14-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.28->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.28->langchain) (23.2)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.28->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.28->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: orjson, mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.10 langchain-community-0.0.25 langchain-core-0.1.28 langchain-text-splitters-0.0.1 langsmith-0.1.14 marshmallow-3.21.0 mypy-extensions-1.0.0 orjson-3.9.15 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain"
      ],
      "metadata": {
        "id": "mvy6Z0PVZfd5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_description = \"\"\"sunny savita is a student of computer science at IIT delhi. He is an indian and has a 8.5 GPA. Sunny is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating\"\"\""
      ],
      "metadata": {
        "id": "QeG_VQSKZfgA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_description"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oKvl_PVDCrQn",
        "outputId": "6fa12406-fccf-4339-d0f4-afee08664d73"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"sunny savita is a student of computer science at IIT delhi. He is an indian and has a 8.5 GPA. Sunny is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SUWT6vzdEHhl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A simple prompt to extract info from \"student_description\" in a JSON format.: WE ARE ASKING BASED ON SOME DESCRIPTION\n",
        "\n",
        "prompt = f'''\n",
        "Please extract the following information from the given text and return it as a JSON object:\n",
        "name\n",
        "college\n",
        "grades\n",
        "club\n",
        "\n",
        "This is the body of text to extract the information from:\n",
        "{student_description}\n",
        "'''\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "cqRi0OHAEHj5",
        "outputId": "71776ea7-7d9d-4d21-b9e2-aeaa5f105194"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nPlease extract the following information from the given text and return it as a JSON object:\\nname\\ncollege\\ngrades\\nclub\\n\\nThis is the body of text to extract the information from:\\nsunny savita is a student of computer science at IIT delhi. He is an indian and has a 8.5 GPA. Sunny is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pass this prompt to chatgpt\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI( api_key = OPENAIAPIKEY )\n",
        "client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFS0lF-wEHmS",
        "outputId": "caf6dc59-52df-45e8-98b2-22c7ff22439f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<openai.OpenAI at 0x7966c48c7400>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FEW SHOTS PROMPT\n",
        "response1 = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\":\"user\",\n",
        "            \"content\":prompt\n",
        "        }\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "Qcv52THrEHoi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kehAw7QrEHqj",
        "outputId": "a4eaf5d5-74d4-4c3f-d43a-750051506afe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-8z3kxC7eK4t4rz51ZkD5YJULJH0fF', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"name\": \"Sunny Savita\",\\n  \"college\": \"IIT Delhi\",\\n  \"grades\": 8.5,\\n  \"club\": \"AI Club\"\\n}', role='assistant', function_call=None, tool_calls=None))], created=1709563139, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_2b778c6b35', usage=CompletionUsage(completion_tokens=38, prompt_tokens=105, total_tokens=143))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response1.choices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gC7RCMjBEHs1",
        "outputId": "04bba939-9689-4541-8eff-fd50634061b6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"name\": \"Sunny Savita\",\\n  \"college\": \"IIT Delhi\",\\n  \"grades\": 8.5,\\n  \"club\": \"AI Club\"\\n}', role='assistant', function_call=None, tool_calls=None))]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ouput1 = response1.choices[0].message.content\n",
        "ouput1"
      ],
      "metadata": {
        "id": "gGuIpVbIZfiz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8fa54bda-cbfb-42a5-ada3-99cfd83d268b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\\n  \"name\": \"Sunny Savita\",\\n  \"college\": \"IIT Delhi\",\\n  \"grades\": 8.5,\\n  \"club\": \"AI Club\"\\n}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to JSON\n",
        "import json\n",
        "x = json.loads(ouput1)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3H2IbEQ55m_",
        "outputId": "5a0d6cc7-3f27-40e5-d949-7f8b8cd38e01"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'Sunny Savita',\n",
              " 'college': 'IIT Delhi',\n",
              " 'grades': 8.5,\n",
              " 'club': 'AI Club'}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x['name'], x['college'], x['grades'], x['club']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9RerX0g55pC",
        "outputId": "279eda7b-9707-47be-b82e-be26fe0640f4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Sunny Savita', 'IIT Delhi', 8.5, 'AI Club')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4tm-OCzk55rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a bit advance function\n",
        "student_custom_function = [\n",
        "    {\n",
        "        'name': 'extract_student_info',\n",
        "        'description': 'Get the student information from the body of the input text',\n",
        "        'parameters': {\n",
        "            'type': 'object',\n",
        "            'properties': {\n",
        "                'name': {\n",
        "                    'type': 'string',\n",
        "                    'description': 'Name of the person'\n",
        "                },\n",
        "                'college': {\n",
        "                    'type': 'string',\n",
        "                    'description': 'The college name.'\n",
        "                },\n",
        "                'grades': {\n",
        "                    'type': 'integer',\n",
        "                    'description': 'CGPA of the student.'\n",
        "                },\n",
        "                'club': {\n",
        "                    'type': 'string',\n",
        "                    'description': 'college club for extracurricular activities. '\n",
        "                }\n",
        "\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "B_bSMZRk55tY"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FEW SHOTS PROMPT\n",
        "response2 = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{            \"role\":\"user\",            \"content\":prompt         }],\n",
        "    functions = student_custom_function\n",
        "\n",
        ")\n",
        "\n",
        "response2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcaAPFKG55vF",
        "outputId": "3ce07c56-792c-411b-c962-597d169da611"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-8z4ai8xPxaUW4llUqxO7GQO41xiwa', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{}', name='extract_student_info'), tool_calls=None))], created=1709566348, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_2b778c6b35', usage=CompletionUsage(completion_tokens=11, prompt_tokens=190, total_tokens=201))"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output2 = response2.choices[0].message.content\n",
        "output2"
      ],
      "metadata": {
        "id": "aU6Wdepw551T"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ToFGegEaCbVN",
        "outputId": "e8dbcd20-ee48-4fb5-c468-02128cd16fa4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nPlease extract the following information from the given text and return it as a JSON object:\\nname\\ncollege\\ngrades\\nclub\\n\\nThis is the body of text to extract the information from:\\nsunny savita is a student of computer science at IIT delhi. He is an indian and has a 8.5 GPA. Sunny is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GploUV3EF6jl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}